{
  "scan_workspace": {
    "name": "scan_workspace",
    "description": "Scans the workspace and returns a list of files with their basic metadata.\nUseful to understand the project structure, file sizes, and modification times.\n\nReturns:\n    list: A list of dictionaries, each containing 'path', 'size' (bytes), and 'last_modified'.",
    "func": "def scan_workspace(workspace_path: str) -> list:\n    \"\"\"\n    Scans the workspace and returns a list of files with their basic metadata.\n    Useful to understand the project structure, file sizes, and modification times.\n    \n    Returns:\n        list: A list of dictionaries, each containing 'path', 'size' (bytes), and 'last_modified'.\n    \"\"\"\n    file_list = []\n    ignore_dirs = {'.git', 'node_modules', '__pycache__', '.vscode', 'dist', 'build', 'coverage', '.wand'}\n    \n    for root, dirs, files in os.walk(workspace_path):\n        dirs[:] = [d for d in dirs if d not in ignore_dirs]\n        \n        for file in files:\n            if file.startswith('.'): continue\n            file_path = os.path.join(root, file)\n            try:\n                stats = os.stat(file_path)\n                file_info = {\n                    \"path\": file_path,\n                    \"size\": stats.st_size,\n                    \"last_modified\": datetime.fromtimestamp(stats.st_mtime).isoformat()\n                }\n                file_list.append(file_info)\n            except Exception:\n                file_list.append({\"path\": file_path, \"size\": -1, \"last_modified\": \"Unknown\"})\n    return file_list",
    "permission_level": 6,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  },
  "read_file": {
    "name": "read_file",
    "description": "Reads the content of a file. \nSupports text files and PDF (if pypdf is installed).",
    "func": "def read_file(file_path: str) -> str:\n    \"\"\"\n    Reads the content of a file. \n    Supports text files and PDF (if pypdf is installed).\n    \"\"\"\n    if not os.path.exists(file_path):\n        return f\"Error: File not found: {file_path}\"\n\n    ext = os.path.splitext(file_path)[1].lower()\n    \n    if ext == '.pdf':\n        try:\n            from pypdf import PdfReader\n            reader = PdfReader(file_path)\n            text_list = []\n            for page in reader.pages:\n                text_list.append(page.extract_text())\n            return \"\\n\".join(text_list)\n        except ImportError:\n            return \"Error: PDF file detected but pypdf is not installed.\"\n        except Exception as e:\n            return f\"Error reading PDF: {str(e)}\"\n    \n    if _is_binary_file(file_path):\n        return f\"Error: File {os.path.basename(file_path)} appears to be binary.\"\n    \n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n            content = f.read()\n            if len(content) > 50000:\n                return content[:50000] + \"\\n...[Content truncated]...\"\n            return content\n    except Exception as e:\n        return f\"Error reading file: {str(e)}\"",
    "permission_level": 6,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  },
  "create_tool": {
    "name": "create_tool",
    "description": "Creates a new tool based on the given requirement description.\nThe tool is created in MEMORY only. To save it permanently, the user must confirm.\n\nArgs:\n    requirement: A detailed description of what the tool should do. It should include a standard comment template with a detailed description, Args (with input examples), and Returns to ensure clear input formats.",
    "func": "def create_tool(requirement: str):\n    \"\"\"\n    Creates a new tool based on the given requirement description.\n    The tool is created in MEMORY only. To save it permanently, the user must confirm.\n    \n    Args:\n        requirement: A detailed description of what the tool should do. It should include a standard comment template with a detailed description, Args (with input examples), and Returns to ensure clear input formats.\n    \"\"\"\n    if not LLM_CONFIG:\n        return \"Error: LLM configuration not set. Cannot use Code Agent.\"\n\n    # 1. Construct Prompt for Code Agent\n    system_prompt = \"\"\"You are an expert Python developer specializing in creating tools for an AI assistant.\nYour task is to write a Python function based on the user's requirement.\n\nRules:\n1. The function must be generic and reusable.\n2. The function must be fully self-contained (import necessary modules inside the function).\n3. The function must have a standard docstring including a detailed description, an 'Args:' section with clear types and input examples for each parameter to avoid ambiguity, and a 'Returns:' section. If an argument is a file path, explicitly describe the expected file format.\n4. The function name should be snake_case and descriptive.\n5. You must output the code inside a markdown code block: ```python ... ```\n6. You must also provide a short description and the function name.\n7. Do NOT use `print` for output; return the result.\n8. Handle errors gracefully and return error messages as strings if needed.\n9. Do NOT include the @register_tool decorator in your output; it will be added automatically.\n\nOutput Format:\nName: <function_name>\nDescription: <short_description>\nCode:\n```python\ndef function_name(...):\n    \\\"\\\"\\\"\n    Detailed description of the function.\n\n    Args:\n        param1 (type): Description. Example: \"example_value\"\n    \n    Returns:\n        type: Description of return value.\n    \\\"\\\"\\\"\n    ...\n```\n\"\"\"\n    \n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": f\"Create a tool for this requirement: {requirement}\"}\n    ]\n\n    max_retries = 3\n    last_error = None\n\n    for attempt in range(max_retries):\n        # 2. Call LLM\n        try:\n            # Use standardTextModel for code generation if available (usually smarter), \n            # otherwise fallback to high speed model.\n            model = LLM_CONFIG.get('standardTextModel') or LLM_CONFIG.get('highSpeedTextModel')\n            \n            response = chat_completion(\n                api_key=LLM_CONFIG.get('apiKey'),\n                base_url=LLM_CONFIG.get('baseUrl'),\n                model=model,\n                messages=messages\n            )\n        except Exception as e:\n            return f\"Error calling Code Agent: {str(e)}\"\n\n        # 3. Parse Response\n        name_match = re.search(r\"Name:\\s*(.+)\", response)\n        desc_match = re.search(r\"Description:\\s*(.+)\", response)\n        code_match = re.search(r\"```python\\s*(.*?)\\s*```\", response, re.DOTALL)\n\n        name = None\n        description = None\n        code = None\n\n        if name_match and desc_match and code_match:\n            name = name_match.group(1).strip()\n            code = code_match.group(1).strip()\n            # Prefer docstring\n            docstring_match = re.search(r'\"\"\"(.*?)\"\"\"', code, re.DOTALL)\n            if docstring_match:\n                description = docstring_match.group(1).strip()\n            else:\n                description = desc_match.group(1).strip()\n        elif code_match:\n            # Fallback\n            code = code_match.group(1).strip()\n            def_match = re.search(r\"def\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s*\\(\", code)\n            if def_match:\n                name = def_match.group(1)\n                docstring_match = re.search(r'\"\"\"(.*?)\"\"\"', code, re.DOTALL)\n                if docstring_match:\n                    description = docstring_match.group(1).strip()\n                else:\n                    description = requirement\n        \n        if not name or not code:\n             last_error = \"Failed to parse output format.\"\n             messages.append({\"role\": \"assistant\", \"content\": response})\n             messages.append({\"role\": \"user\", \"content\": f\"Error: {last_error} Please ensure you follow the Output Format exactly.\"})\n             continue\n\n        # 4. Sandbox Verification\n        try:\n            # Syntax Check\n            compile(code, '<string>', 'exec')\n            \n            # Definition Check\n            sandbox_globals = {}\n            # We might need to mock imports or provide context if the tool relies on them, \n            # but the prompt says \"self-contained\".\n            exec(code, sandbox_globals)\n            \n            if name not in sandbox_globals:\n                raise ValueError(f\"Function '{name}' was not defined in the generated code.\")\n            \n            if not callable(sandbox_globals[name]):\n                raise ValueError(f\"'{name}' is not a callable function.\")\n\n            # If successful, register\n            return _register_tool_memory(name, code, description)\n\n        except Exception as verify_err:\n            last_error = f\"Sandbox Verification Failed: {str(verify_err)}\"\n            messages.append({\"role\": \"assistant\", \"content\": response})\n            messages.append({\"role\": \"user\", \"content\": f\"The code you generated failed verification:\\n{last_error}\\n\\nPlease fix the code and output the full corrected response following the same format.\"})\n            continue\n\n    return f\"Failed to create tool after {max_retries} attempts. Last error: {last_error}\"",
    "permission_level": 9,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  },
  "list_files": {
    "name": "list_files",
    "description": "Lists files in a specific directory.",
    "func": "def list_files(directory_path: str) -> list:\n    \"\"\"\n    Lists files in a specific directory.\n    \"\"\"\n    try:\n        return os.listdir(directory_path)\n    except Exception as e:\n        return [f\"Error: {str(e)}\"]",
    "permission_level": 6,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  },
  "write_file": {
    "name": "write_file",
    "description": "Writes text content to a specified file path, creating the file if it doesn't exist or overwriting it if it does.\n\nArgs:\n    file_path (str): The path to the file where content will be written.\n    content (str): The text content to write to the file.\n\nReturns:\n    str: Success message if writing is successful, or error message if an exception occurs.",
    "func": "def write_file(file_path, content):\n    \"\"\"\n    Writes text content to a specified file path, creating the file if it doesn't exist or overwriting it if it does.\n\n    Args:\n        file_path (str): The path to the file where content will be written.\n        content (str): The text content to write to the file.\n\n    Returns:\n        str: Success message if writing is successful, or error message if an exception occurs.\n    \"\"\"\n    try:\n        with open(file_path, 'w', encoding='utf-8') as f:\n            f.write(content)\n        return f\"Successfully wrote content to {file_path}\"\n    except Exception as e:\n        return f\"Error writing to file: {str(e)}\"",
    "permission_level": 8,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  },
  "edit_file": {
    "name": "edit_file",
    "description": "Edits a file by replacing a specific text segment with new text.\n\n**Preference**: Use this tool for ALL modification tasks (add, delete, update) on existing files. \nUse 'write_file' only for creating new files or completely overwriting files.\n\nStrategies:\n- Modify: Set 'old_text' to the content you want to change, and 'new_text' to the desired content.\n- Delete: Set 'old_text' to the content you want to remove, and 'new_text' to an empty string \"\".\n- Add: Select a unique anchor line as 'old_text', and set 'new_text' to \"anchor\\nnew_content\" (to add after) or \"new_content\\nanchor\" (to add before).\n\nArgs:\n    file_path (str): The absolute path to the file.\n    old_text (str): The exact text segment to be replaced. Must be unique in the file.\n    new_text (str): The new text to replace the old text with.\n    \nReturns:\n    str: Success or error message.",
    "func": "def edit_file(file_path: str, old_text: str, new_text: str):\n    \"\"\"\n    Edits a file by replacing a specific text segment with new text.\n    \n    **Preference**: Use this tool for ALL modification tasks (add, delete, update) on existing files. \n    Use 'write_file' only for creating new files or completely overwriting files.\n\n    Strategies:\n    - Modify: Set 'old_text' to the content you want to change, and 'new_text' to the desired content.\n    - Delete: Set 'old_text' to the content you want to remove, and 'new_text' to an empty string \"\".\n    - Add: Select a unique anchor line as 'old_text', and set 'new_text' to \"anchor\\\\nnew_content\" (to add after) or \"new_content\\\\nanchor\" (to add before).\n    \n    Args:\n        file_path (str): The absolute path to the file.\n        old_text (str): The exact text segment to be replaced. Must be unique in the file.\n        new_text (str): The new text to replace the old text with.\n        \n    Returns:\n        str: Success or error message.\n    \"\"\"\n    if not os.path.exists(file_path):\n        return f\"Error: File not found: {file_path}\"\n        \n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n            \n        # Normalize line endings to \\n for consistent matching\n        old_text_normalized = old_text.replace('\\r\\n', '\\n')\n        new_text_normalized = new_text.replace('\\r\\n', '\\n')\n            \n        if old_text_normalized not in content:\n            # Fallback: Try stripping leading/trailing whitespace from old_text\n            old_text_stripped = old_text_normalized.strip()\n            if old_text_stripped and old_text_stripped in content:\n                count = content.count(old_text_stripped)\n                if count == 1:\n                    # Found a unique match with stripped version\n                    new_content = content.replace(old_text_stripped, new_text_normalized, 1)\n                    with open(file_path, 'w', encoding='utf-8') as f:\n                        f.write(new_content)\n                    return f\"Successfully edited {file_path} (matched with stripped whitespace)\"\n                elif count > 1:\n                    return f\"Error: 'old_text' not found exactly. A stripped version was found {count} times. Please provide more context.\"\n            \n            return \"Error: 'old_text' not found in the file. Please ensure exact match including whitespace and indentation.\"\n            \n        count = content.count(old_text_normalized)\n        if count > 1:\n            return f\"Error: 'old_text' found {count} times. Please provide more context in 'old_text' to make it unique.\"\n            \n        new_content = content.replace(old_text_normalized, new_text_normalized, 1)\n        \n        with open(file_path, 'w', encoding='utf-8') as f:\n            f.write(new_content)\n            \n        return f\"Successfully edited {file_path}\"\n    except Exception as e:\n        return f\"Error editing file: {str(e)}\"",
    "permission_level": 8,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  },
  "get_workspace_content_index": {
    "name": "get_workspace_content_index",
    "description": "Retrieves and updates the workspace content index with LLM-generated summaries.\n\nDifference from 'scan_workspace':\n- 'scan_workspace': Quickly lists file paths and basic metadata (structure only).\n- 'get_workspace_content_index': Analyzes file content to generate semantic summaries, helping the model understand the purpose of each file.\n\nReturns:\n    str: The JSON string of the updated workspace index (Merkle Tree), containing file paths and descriptions.",
    "func": "def get_workspace_content_index():\n    \"\"\"\n    Retrieves and updates the workspace content index with LLM-generated summaries.\n    \n    Difference from 'scan_workspace':\n    - 'scan_workspace': Quickly lists file paths and basic metadata (structure only).\n    - 'get_workspace_content_index': Analyzes file content to generate semantic summaries, helping the model understand the purpose of each file.\n\n    Returns:\n        str: The JSON string of the updated workspace index (Merkle Tree), containing file paths and descriptions.\n    \"\"\"\n    # Use current working directory as workspace root\n    workspace_path = os.getcwd()\n    \n    index_dir = os.path.join(workspace_path, '.wand')\n    if not os.path.exists(index_dir):\n        os.makedirs(index_dir)\n    \n    index_file = os.path.join(index_dir, 'workspace_index.json')\n    \n    # Load existing index\n    old_index = {}\n    if os.path.exists(index_file):\n        try:\n            with open(index_file, 'r', encoding='utf-8') as f:\n                old_index = json.load(f)\n        except:\n            pass\n\n    new_index = {}\n    ignore_dirs = {'.git', 'node_modules', '__pycache__', '.vscode', 'dist', 'build', 'coverage', '.wand'}\n    \n    # 1. Scan and Calculate Hash\n    files_to_process = []\n    \n    for root, dirs, files in os.walk(workspace_path):\n        dirs[:] = [d for d in dirs if d not in ignore_dirs]\n        \n        for file in files:\n            if file.startswith('.'): continue\n            file_path = os.path.join(root, file)\n            rel_path = os.path.relpath(file_path, workspace_path)\n            \n            try:\n                with open(file_path, 'rb') as f:\n                    content = f.read()\n                    file_hash = hashlib.md5(content).hexdigest()\n                    \n                # Check if changed\n                if rel_path in old_index and old_index[rel_path].get('hash') == file_hash:\n                    new_index[rel_path] = old_index[rel_path]\n                else:\n                    # Needs update\n                    files_to_process.append((rel_path, file_path, file_hash))\n            except Exception as e:\n                print(f\"Error processing {rel_path}: {e}\")\n\n    # 2. Generate Descriptions for changed files\n    if not LLM_CONFIG:\n        return \"Error: LLM configuration not set.\"\n        \n    model = LLM_CONFIG.get('highSpeedTextModel') or LLM_CONFIG.get('standardTextModel')\n    api_key = LLM_CONFIG.get('apiKey')\n    base_url = LLM_CONFIG.get('baseUrl')\n\n    updated_count = 0\n\n    def process_file_item(item):\n        rel_path, file_path, file_hash = item\n        \n        # Read content (text only)\n        if _is_binary_file(file_path):\n             return rel_path, {\n                \"hash\": file_hash,\n                \"path\": file_path,\n                \"description\": \"[Binary File]\"\n            }\n\n        try:\n            with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n                content = f.read(10000) # Limit context\n            \n            prompt = f\"Please describe the contents of this file. Keep the description concise and under 300 words. The goal is to allow the LLM to understand what is inside this file from a global perspective.\\n\\nFile: {rel_path}\\n\\nContent:\\n{content}\"\n            \n            messages = [{\"role\": \"user\", \"content\": prompt}]\n            \n            try:\n                response = chat_completion(api_key, base_url, model, messages)\n                description = response.strip()\n            except Exception as e:\n                description = f\"Error generating description: {str(e)}\"\n            \n            return rel_path, {\n                \"hash\": file_hash,\n                \"path\": file_path,\n                \"description\": description,\n                \"last_modified\": datetime.now().isoformat()\n            }\n            \n        except Exception as e:\n             return rel_path, {\n                \"hash\": file_hash,\n                \"path\": file_path,\n                \"description\": f\"Error reading file: {str(e)}\"\n            }\n\n    # Use ThreadPoolExecutor for parallel processing\n    if files_to_process:\n        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n            future_to_file = {executor.submit(process_file_item, item): item for item in files_to_process}\n            for future in concurrent.futures.as_completed(future_to_file):\n                try:\n                    rel_path, result_data = future.result()\n                    new_index[rel_path] = result_data\n                    updated_count += 1\n                except Exception as e:\n                    print(f\"Error in thread processing: {e}\")\n\n    # 3. Save Index\n    try:\n        with open(index_file, 'w', encoding='utf-8') as f:\n            json.dump(new_index, f, indent=2, ensure_ascii=False)\n    except Exception as e:\n        return f\"Error saving index: {str(e)}\"\n\n    # Return index without hashes to save context\n    sanitized_index = {k: {key: val for key, val in v.items() if key != 'hash'} for k, v in new_index.items()}\n    return json.dumps(sanitized_index, ensure_ascii=False)",
    "permission_level": 8,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  },
  "check_available_tools": {
    "name": "check_available_tools",
    "description": "Checks and returns the list of currently available (enabled) tools.\nUseful for the AI to know what capabilities it currently has.\n\nReturns:\n    list: A list of tool names and their descriptions.",
    "func": "def check_available_tools() -> list:\n    \"\"\"\n    Checks and returns the list of currently available (enabled) tools.\n    Useful for the AI to know what capabilities it currently has.\n    \n    Returns:\n        list: A list of tool names and their descriptions.\n    \"\"\"\n    tools = []\n    for name, tool in P10Config.TOOLS.get_visible_tools().items():\n        tools.append({\n            \"name\": name,\n            \"description\": tool.description.strip().split('\\n')[0], # First line of description\n            \"is_gen\": tool.is_gen,\n            \"tool_type\": tool.tool_type\n        })\n    return tools",
    "permission_level": 5,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  },
  "get_tools_status": {
    "name": "get_tools_status",
    "description": "Returns the detailed status of all registered tools (including hidden ones).\n\nReturns:\n    list: A list of tool metadata objects (name, description, is_visible, permission_level, is_gen).",
    "func": "def get_tools_status() -> list:\n    \"\"\"\n    Returns the detailed status of all registered tools (including hidden ones).\n    \n    Returns:\n        list: A list of tool metadata objects (name, description, is_visible, permission_level, is_gen).\n    \"\"\"\n    return list(P10Config.TOOLS.get_all_tools().values())",
    "permission_level": 10,
    "is_visible": true,
    "is_gen": false,
    "tool_type": "general",
    "metadata": {}
  }
}